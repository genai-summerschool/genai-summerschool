---
layout: default
title: Sustainable AI for the Future Web
description: Workshop @ The Web Conference 2025
---

**Welcome to The Workshop on Sustainable AI for the Future Web at The Web Conference 2025!**

---

## **Schedule** {#schedule}

**Location: TBD**

---
## **Important Dates** {#dates}

| Submission Open | **Dec 5, 2024 (AoE)** |
| Submission Deadline | **<strike>Dec 24, 2024</strike>** |
| Decision Notification | **March 7, 2025 (AoE)** |
| Camera-Ready Deadline | **March 14, 2025 (AoE)** |
| Workshop Date | **Apr 28 PM, 2024 (TBD)** |

---



<!-- ---

## **Program Committee** {#Committee}

Coming soon -->

---

## **Organizers** {#organizers}
<div class="container">

<figure>
    <a href="http://changxu.xyz/">
    <img class="img-author" src="assets/imgs/authors/chang_xu.jpeg" alt="Chang Xu"/></a>
    <b><br><a href="http://changxu.xyz/">Chang Xu</a>
    <br>The University of Sydney</b>
</figure>

<figure>
    <a href="https://yunke-wang.github.io">
    <img class="img-author" src="" alt="Yunke Wang"/></a>
    <b><br><a href="https://yunke-wang.github.io">Yunke Wang</a>
    <br>The University of Sydney</b>
</figure>

<figure>
    <a href="https://ggjy.github.io">
    <img class="img-author" src="assets/imgs/authors/jianyuan.jpg" alt="Jianyuan Guo"/></a>
    <b><br><a href="https://ggjy.github.io">Jianyuan Guo</a>
    <br>The University of Sydney</b>
</figure>

<figure>
    <a href="https://daochang.site/">
    <img class="img-author" src="assets/imgs/authors/daochang_liu.jpg" alt="Daochang Liu"/></a>
    <b><br><a href="https://daochang.site/">Daochang Liu</a>
    <br>The University of Sydney</b>
</figure>

<figure>
    <a href="https://www.cs.cityu.edu.hk/~minjdong/">
    <img class="img-author" src="assets/imgs/authors/minjing_dong.png" alt="Minjing Dong"/></a>
    <b><br><a href="https://www.cs.cityu.edu.hk/~minjdong/">Minjing Dong</a>
    <br>City University of Hong Kong</b>
</figure>


<figure>
    <a href="https://research.monash.edu/en/persons/yasmeen-george">
    <img class="img-author" src="assets/imgs/authors/yasmeen_george.png" alt="Yasmeen George"/></a>
    <b><br><a href="https://research.monash.edu/en/persons/yasmeen-george">Yasmeen George</a>
    <br>Monash University</b>
</figure>

<figure>
    <a href="https://scholars.uow.edu.au/johan-barthelemy">
    <img class="img-author" src="assets/imgs/authors/johan.jpeg" alt="Johan Barthélemy"/></a>
    <b><br><a href="https://scholars.uow.edu.au/johan-barthelemy">Johan Barthélemy</a>
    <br>NVIDIA</b>
</figure>

<figure>
    <a href="https://sites.google.com/view/yanliu-ai/home">
    <img class="img-author" src="assets/imgs/authors/yanliu.jpeg" alt="Yan Liu"/></a>
    <b><br><a href="https://sites.google.com/view/yanliu-ai/home">Yan Liu</a>
    <br>NVIDIA</b>
</figure>

<figure>
    <a href="https://profiles.uts.edu.au/Ling.Chen">
    <img class="img-author" src="assets/imgs/authors/lingchen.jpeg" alt="Ling Chen"/></a>
    <b><br><a href="https://profiles.uts.edu.au/Ling.Chen">Yan Liu</a>
    <br>University of Technology Sydney</b>
</figure>


</div>


---
## **Contact** {#contact}

Contact the organizers at [mm2024-esgmfm@googlegroups.com](mailto:mm2024-esgmfm@googlegroups.com)


## **<strike>Call for Papers</strike>** {#call}

The rapid progress in foundation models has enhanced the capabilities of multimedia models across a broad spectrum of tasks. Despite their exceptional performance, deploying these models in practical settings raises several concerns, particularly regarding efficiency, security, and generalization. As the utility of foundation models in multimedia topics becomes increasingly evident, addressing these issues is crucial. This workshop focuses on these critical aspects in foundation models, where the scope of the foundation model encompasses a wide range of domains such as vision, language, speech etc., with an emphasis on multimedia tasks and multi-modality methods. 

Therefore, we solicit original research papers in (but not limited to) the following topics:

**Efficiency**
- Efficient network design in foundation models
- Training efficiency of foundation models
- Inference efficiency of foundation models

**Security**
- Adversarial robustness of foundation models
- Privacy and memorization in foundation models
- Trustworthiness and alignment of foundation models

**Generalization**
- Generalization across tasks
- Generalization across data
- Generalization across modalities

**Submission Deadline: <strike>July 19, 2024</strike> <span>Extended to July 29</span>**

**Submit Platform: [OpenReview](https://openreview.net/group?id=acmmm.org/ACMMM/2024/Workshop/ESGMFM)**

We welcome submissions of research papers, demos, datasets, and position papers within the workshop's scopes.
The submission guideline follows the main conference site of [ACM Multimedia 2024](https://2024.acmmm.org/), including the formatting guideline and submission policies. 
The review process for this workshop will be "double-blinded”.
Submissions should be of up to 4-page length in [ACM-MM format](https://2024.acmmm.org/files/ACM-MM24-paper-templates.zip), plus up to 1 additional page for the references.

All papers will be peer-reviewed by at least three experts in the field, regarding the relevance to the workshop, scientific novelty, and technical quality. 
Accepted submissions will be presented via oral or poster sessions. 
All accepted papers will be published in the ACM Multimedia proceedings in the ACM Digital Library.

Submit your manuscripts through [OpenReview](https://openreview.net/group?id=acmmm.org/ACMMM/2024/Workshop/ESGMFM).
All the authors need to create a profile on OpenReview. 
New profiles created without an institutional email will go through a moderation process that can take up to two weeks. 
New profiles created with an institutional email will be activated automatically.


<!-- ## Program Committee
## Sponsors -->

